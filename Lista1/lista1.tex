\documentclass[a4paper,12pt]{article}
\usepackage[brazilian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}

\renewcommand{\thesubsection}{\thesection.\alph{subsection}}

\title{CK0031 - Lista 1}
\author{Marcos Felipe De Menezes Mota - 354080}
\date{}

\begin{document}
\maketitle
\section{Questão 1}

\subsection{}
Falso, pois um agente com apenas informação parcial sobre o estado do mundo pode gerar um função de probabilidade para as ações. Com a nossa definição de racionalidade baseado em maximação de um função de desempenho, podemos dizer que um agente é perfeitamente racional mesmo se ele maximizar uma função probabilística de desempenho e ações.

\subsection{}
Verdadeiro, pois em ambientes sequenciais um agente reflex iria apenas agir baseado no percept atual mas a caracteristica desses ambientes são, que ações efeitas no presente pode afetar as ações a serem tomadas no futuro. Como agentes reflex não tem essa habildade, nunca poderam selecionar suas ações baseadas na melhora de uma madida de desempenho para esse ambiente.

\subsection{}
Verdadeiro. Um componente essencial de um task environment é a medida de performace. Logo se atribuirmos uma media de performace que sempre da a pontuação maxima para qualquer ação, qualquer agente vai ser racional.

\subsection{}
Falso. Um agent program tem como entrada um percept atual do ambiente. Já uma agent function tem como entrada o histórico de percepts.

\subsection{}
Falso. Em geral agent functions são infinitas a não ser que haja uma restrição no tamanho da lista de percepts que podem ser usadas. Logo, agent functions são objetos matemáticos que não implicam em implementação.

\subsection{}

Verdadeiro. Por exemplo usando uma medida de performace do item C obtemos esse tipo de resultado.

\subsection{}

Verdadeiro, pois se existe um ambiente que todo agente é racional se mudarmos os actuators e sensors do task environment o agente ainda será racional.

\subsection{}
Falso. Se o ambiente não pode ser percebido a racionalidade do agente vem do conhcimento interno modelado no agente. Se esse modelo for mal feito o agente não tomará ações para maximizar a performace e logo não são racionais.

\subsection{}

Falso. Por mais que o agente tome sempre as decisões mais racionais possiveis o ambiente não pode ser completamente observável e fatores como blefe não permitem uma modelagem matemática determinística.

\section{Questão 2}
\subsection{Playing Soccer}
\subsubsection{PEAS}
\begin{table}[h!]
\begin{tabular}{l|l|l|l}
\hline
Performace & Environment & Actuators & Sensors \\
\hline
Número de Gols & Campo de Futebol & Pernas & Camera \\
Defesas & & Mãos & Sensor de distância \\
\end{tabular}
\end{table}
\subsubsection{Caracterização}
\begin{table}[h!]
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
partially observable & multi-agent & stochastic & sequential & dynamic & continuous & known
\end{tabular}
\end{table}

\subsection{Shop Books}
\subsubsection{PEAS}
\begin{table}[h!]
\begin{tabular}{l|l|l|l}
\hline
Performace & Environment & Actuators & Sensors \\
\hline
Descontos & Serviço de Compras Online & HTML parser & Listeners \\
Número de livros & & efetuar procedimentos & buscador\\
\end{tabular}
\end{table}
\subsubsection{Caracterização}
\begin{table}[h!]
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
fully observable & single agent & deterministic & episodic & dynamic & discrete & known
\end{tabular}
\end{table}

\subsection{Tennis Match}
\subsubsection{PEAS}
\begin{table}[h!]
\begin{tabular}{l|l|l|l}
\hline
Performace & Environment & Actuators & Sensors \\
\hline
Sets Ganhos & Quadra de Tennis & Mãos & Camera \\
Número de pontos & & Motores & Sensor de distância\\
Velocida de lançamento & & Raquete & osciloscópio\\
\end{tabular}
\end{table}
\subsubsection{Caracterização}
\begin{table}[h!]
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
partially observable & multi-agent & stochastic & sequential & dynamic & continuous & known
\end{tabular}
\end{table}

\subsection{Tennis Match Against Wall}
\subsubsection{PEAS}
\begin{table}[h!]
\begin{tabular}{l|l|l|l}
\hline
Performace & Environment & Actuators & Sensors \\
\hline
Sets Ganhos & Quadra de Tennis & Mãos & Camera \\
Número de pontos & & Motores & Sensor de distância\\
Velocida de lançamento & & Raquete & osciloscópio\\
\end{tabular}
\end{table}
\subsubsection{Caracterização}
\begin{table}[h!]
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
fully observable & single-agent & stochastic & sequential & dynamic & continuous & known
\end{tabular}
\end{table}

\subsection{High Jump}
\subsubsection{PEAS}
\begin{table}[h!]
\begin{tabular}{l|l|l|l}
\hline
Performace & Environment & Actuators & Sensors \\
\hline
Altura & Mundo & Pernas & Camera \\
 & & Motores & Sensor de distância\\
 & & Armortecedores & osciloscópio\\
\end{tabular}
\end{table}
\subsubsection{Caracterização}
\begin{table}[h!]
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
fully observable & single-agent & stochastic & episodic & dynamic & continuous & known
\end{tabular}
\end{table}

\subsection{Biddin at an Auction}
\subsubsection{PEAS}
\begin{table}[h!]
\begin{tabular}{l|l|l|l}
\hline
Performace & Environment & Actuators & Sensors \\
\hline
Comprar Objeto & Leilão & Publicar propostas & Listeners \\
Menor porcentagem de preço & &  & \\
\end{tabular}
\end{table}
\subsubsection{Caracterização}
\begin{table}[h!]
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
fully observable & single-agent & stochastic & episodic & static & discrete & known
\end{tabular}
\end{table}

\section{Questão 3}
\subsection{Agent}
Programa que pode perceber e atuar no ambiente em que ele está inserido.
\subsection{Agent Function}
Apartir de todos os percepts decidir qual ação deverá ser executada em terminado percept.
\subsection{Agent Program}
Função que apartir do estado atual do ambiente decide qual a ação deve ser tomada.
\subsection{Rationality}
Tomar a ação correta no estado atual e pensando em sua consequências futuras aonde a forma de dizer se a ação foi correta é baseada no quão proximo ela te deixou do objetivo.
\subsection{Autonomy}
Tomar boas decisões baseadas apenas nas informações presentes no ambiente e informação do agente, ou seja, sem conhecimento pré-determinado ou passado por outro agente.
\subsection{Reflex Agent}
Agente que apenas leva em conta soment o percept atual do ambiente e realiza sua ação consultando uma tabela de ações pré-determinada para cada percept.
\subsection{Model-Based Agent}
Agente que usa histórico de percepts junto com of efeitos de suas ações no ambiente para escolher a melhor ação no estado atual.
\subsection{Goal-Based Agent}
Esse agente além de de usar os percepts passados como os Model-Based escolhe suas ações baseadas em um conjuto de objetivos que devem ser alcaçados, logo não tem objetivos a longo termo.
\subsection{Utility Agent}
Esse agente diferente do Goal-Based não possuem a noção de objetivo mas escolhe sua ação de forma a maximizar uma função interna chamada função de utilidade.
\subsection{Learn Agent}
Agente que pussui uma forma de critica externa da forma que o agente pode dizer se sua ação foi boa ou não e atualizar seus parametros e possiveis ações para que possa aprender de que forma ele pode melhorar sua performace.

\section{Questão 4}

\subsection{}
Sim é possivel. Como exemplo podemos ter um ambiente bem simples, como o vaccumn world, onde tanto um reflex-agent como um model-based tomam atitudes ótimas assim toda a sequência de percepts teram ações iguais.

\subsection{}
Depende do ambiente, em geral agent program que são adaptados para ambientes estocasticos e dinamicos podem variar suas ações para a mesma sequência de percepts.

\subsection{}
Isso pode mudar a agent function em ambientes dinamicos pois assim mais mudanças no ambiente seram percebidas e o agente pode tomar ações baseadas nessas mudanças e isso pode variar a ação tomada, logo a agent function em si.

\section{Questão 5}

\url{https://github.com/marcosfmmota/CK0031/tree/master/Lista1}

Um reflex agent não conseguiria voltar para a posição inicial pois ele atua simplemente sobre os percepts atuais logo não possui memória sobre o ambiente em que ele esteve anteriormente.

Dessa forma um reflex agent ficaria apenas andando aleatóriamente pelo ambiente e não teria como garantir que todos os humanos do ambiente seria salvos, mas apenas alguns que o agente encontrasse no caminho. O que mais impede o bom desempenho de um reflex agent é a sua falta de memória das ações passadas.

\end{document}
